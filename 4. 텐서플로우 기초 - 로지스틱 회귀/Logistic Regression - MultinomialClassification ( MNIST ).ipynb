{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - MultinomialClassification ( MNIST )\n",
    "softmax를 사용한 로지스틱 다중 분류 예제.   \n",
    "( 딥러닝의 방식인 층을 사용하지 않고 로지스틱회귀로만 푸는 예제 )\n",
    "> 출처\n",
    "1. Andrew NG\n",
    "2. Sung Kim\n",
    "\n",
    "데이터 출처 : MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기 및 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 데이터 불러오기.\n",
    "( train_x, train_y ), (test_x, test_y ) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# MNIST 데이터 파라미터 설정\n",
    "num_classes = 10 # 0부터 9까지의 숫자\n",
    "num_features = 784 # 28*28\n",
    "\n",
    "# 하이퍼파라미터\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "num_data = train_x.shape[0]\n",
    "\n",
    "# 딥러닝이 아닌 간단한 로지스틱 회귀를 위해서 2차원(이미지)를 1차원으로 바꿔준다.\n",
    "train_X = tf.constant(train_x, dtype=tf.float32)\n",
    "train_X = tf.reshape(train_X, [-1,num_features])\n",
    "train_Y = tf.one_hot(train_y, depth=10) # y값 one-hot encoding\n",
    "\n",
    "test_X = tf.constant(test_x, dtype=tf.float32)\n",
    "test_X = tf.reshape(test_X, [-1,num_features])\n",
    "test_Y = tf.one_hot(test_y, depth=10) # y값 one-hot encoding\n",
    "\n",
    "# 데이터 셔플링 및 배치화\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size)\n",
    "iterater = train_data.__iter__()\n",
    "\n",
    "# 파라미터 설정\n",
    "W = tf.Variable(tf.random.normal([num_features,num_classes]))\n",
    "b = tf.Variable(tf.random.normal([num_classes]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설 함수\n",
    "def hypothesis(x):\n",
    "    return tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "# 비용 함수 cross-entropy를 사용한다.\n",
    "def cost_function(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.) # log(0) error를 피하기 위함.\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred),axis=1))\n",
    "\n",
    "# Gradient Descent\n",
    "def run_optimizer(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predict = hypothesis(x)\n",
    "        cost = cost_function(y, predict)\n",
    "\n",
    "    dJ_dW,dJ_db = tape.gradient(cost,[W,b])\n",
    "    W.assign_sub(learning_rate*dJ_dW)\n",
    "    b.assign_sub(learning_rate*dJ_db)\n",
    "    \n",
    "def accuracy(y_true, y_pred):\n",
    "    predict = tf.argmax(y_pred, axis=1)\n",
    "    y_true = tf.argmax(y_true,axis=1)\n",
    "    correct = tf.cast(tf.equal(predict,y_true),dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 17.738817 train_accuracy: 0.1433 test_accuracy: 0.1407\n",
      "epoch: 1 cost: 15.948948 train_accuracy: 0.22976667 test_accuracy: 0.2297\n",
      "epoch: 2 cost: 15.109477 train_accuracy: 0.27038333 test_accuracy: 0.2698\n",
      "epoch: 3 cost: 14.590966 train_accuracy: 0.29536667 test_accuracy: 0.2929\n",
      "epoch: 4 cost: 14.132969 train_accuracy: 0.31743333 test_accuracy: 0.3146\n",
      "epoch: 5 cost: 13.83599 train_accuracy: 0.33198333 test_accuracy: 0.3277\n",
      "epoch: 6 cost: 13.738941 train_accuracy: 0.33668333 test_accuracy: 0.3337\n",
      "epoch: 7 cost: 13.5963955 train_accuracy: 0.34335 test_accuracy: 0.3419\n",
      "epoch: 8 cost: 13.459977 train_accuracy: 0.35013333 test_accuracy: 0.3492\n",
      "epoch: 9 cost: 13.329876 train_accuracy: 0.35646668 test_accuracy: 0.3565\n",
      "epoch: 10 cost: 13.198906 train_accuracy: 0.36271667 test_accuracy: 0.3638\n",
      "epoch: 11 cost: 13.087333 train_accuracy: 0.3682 test_accuracy: 0.3715\n",
      "epoch: 12 cost: 13.01638 train_accuracy: 0.37153333 test_accuracy: 0.3774\n",
      "epoch: 13 cost: 12.908867 train_accuracy: 0.3767 test_accuracy: 0.3822\n",
      "epoch: 14 cost: 12.742627 train_accuracy: 0.38468334 test_accuracy: 0.3889\n",
      "epoch: 15 cost: 12.500656 train_accuracy: 0.39623332 test_accuracy: 0.3995\n",
      "epoch: 16 cost: 12.45863 train_accuracy: 0.39826667 test_accuracy: 0.4\n",
      "epoch: 17 cost: 12.21165 train_accuracy: 0.41013333 test_accuracy: 0.4143\n",
      "epoch: 18 cost: 12.166264 train_accuracy: 0.41236666 test_accuracy: 0.4144\n",
      "epoch: 19 cost: 12.057926 train_accuracy: 0.41788334 test_accuracy: 0.4195\n",
      "epoch: 20 cost: 11.959319 train_accuracy: 0.4227 test_accuracy: 0.4238\n",
      "epoch: 21 cost: 11.894348 train_accuracy: 0.42576668 test_accuracy: 0.4274\n",
      "epoch: 22 cost: 11.809982 train_accuracy: 0.42965 test_accuracy: 0.4331\n",
      "epoch: 23 cost: 11.534757 train_accuracy: 0.4428 test_accuracy: 0.4448\n",
      "epoch: 24 cost: 11.218655 train_accuracy: 0.45806667 test_accuracy: 0.4639\n",
      "epoch: 25 cost: 10.994285 train_accuracy: 0.46888334 test_accuracy: 0.4741\n",
      "epoch: 26 cost: 10.665093 train_accuracy: 0.48473334 test_accuracy: 0.4866\n",
      "epoch: 27 cost: 10.428291 train_accuracy: 0.4961 test_accuracy: 0.4998\n",
      "epoch: 28 cost: 10.204967 train_accuracy: 0.5071333 test_accuracy: 0.5105\n",
      "epoch: 29 cost: 10.094056 train_accuracy: 0.5122667 test_accuracy: 0.5137\n",
      "epoch: 30 cost: 9.977379 train_accuracy: 0.518 test_accuracy: 0.5206\n",
      "epoch: 31 cost: 9.913019 train_accuracy: 0.5211833 test_accuracy: 0.5216\n",
      "epoch: 32 cost: 9.851697 train_accuracy: 0.52426666 test_accuracy: 0.5269\n",
      "epoch: 33 cost: 9.81348 train_accuracy: 0.52595 test_accuracy: 0.5286\n",
      "epoch: 34 cost: 9.797116 train_accuracy: 0.5268 test_accuracy: 0.5284\n",
      "epoch: 35 cost: 9.778596 train_accuracy: 0.5276833 test_accuracy: 0.5286\n",
      "epoch: 36 cost: 9.736326 train_accuracy: 0.5298333 test_accuracy: 0.5305\n",
      "epoch: 37 cost: 9.703884 train_accuracy: 0.53135 test_accuracy: 0.532\n",
      "epoch: 38 cost: 9.696092 train_accuracy: 0.53176665 test_accuracy: 0.5319\n",
      "epoch: 39 cost: 9.686937 train_accuracy: 0.53211665 test_accuracy: 0.5327\n",
      "epoch: 40 cost: 9.669173 train_accuracy: 0.5330167 test_accuracy: 0.5336\n",
      "epoch: 41 cost: 9.605652 train_accuracy: 0.53611666 test_accuracy: 0.537\n",
      "epoch: 42 cost: 9.580503 train_accuracy: 0.53735 test_accuracy: 0.5378\n",
      "epoch: 43 cost: 9.622893 train_accuracy: 0.53525 test_accuracy: 0.5367\n",
      "epoch: 44 cost: 9.586013 train_accuracy: 0.5369833 test_accuracy: 0.5374\n",
      "epoch: 45 cost: 9.571404 train_accuracy: 0.53785 test_accuracy: 0.5384\n",
      "epoch: 46 cost: 9.524839 train_accuracy: 0.54005 test_accuracy: 0.5395\n",
      "epoch: 47 cost: 9.525342 train_accuracy: 0.54008335 test_accuracy: 0.5407\n",
      "epoch: 48 cost: 9.502113 train_accuracy: 0.5412 test_accuracy: 0.5413\n",
      "epoch: 49 cost: 9.511026 train_accuracy: 0.54065 test_accuracy: 0.5433\n",
      "epoch: 50 cost: 9.515757 train_accuracy: 0.54035 test_accuracy: 0.5406\n",
      "epoch: 51 cost: 9.468088 train_accuracy: 0.5427167 test_accuracy: 0.5422\n",
      "epoch: 52 cost: 9.457899 train_accuracy: 0.54325 test_accuracy: 0.5421\n",
      "epoch: 53 cost: 9.423623 train_accuracy: 0.54495 test_accuracy: 0.5429\n",
      "epoch: 54 cost: 9.412473 train_accuracy: 0.5455833 test_accuracy: 0.5448\n",
      "epoch: 55 cost: 9.401474 train_accuracy: 0.5460167 test_accuracy: 0.544\n",
      "epoch: 56 cost: 9.416977 train_accuracy: 0.5453 test_accuracy: 0.5452\n",
      "epoch: 57 cost: 9.402196 train_accuracy: 0.5461 test_accuracy: 0.5446\n",
      "epoch: 58 cost: 9.385583 train_accuracy: 0.54685 test_accuracy: 0.5437\n",
      "epoch: 59 cost: 9.3955 train_accuracy: 0.5463167 test_accuracy: 0.5442\n",
      "epoch: 60 cost: 9.3790045 train_accuracy: 0.5470667 test_accuracy: 0.547\n",
      "epoch: 61 cost: 9.370489 train_accuracy: 0.5474833 test_accuracy: 0.5465\n",
      "epoch: 62 cost: 9.399524 train_accuracy: 0.5461 test_accuracy: 0.5456\n",
      "epoch: 63 cost: 9.336645 train_accuracy: 0.5492 test_accuracy: 0.5483\n",
      "epoch: 64 cost: 9.336039 train_accuracy: 0.5491167 test_accuracy: 0.5484\n",
      "epoch: 65 cost: 9.356241 train_accuracy: 0.54831666 test_accuracy: 0.5473\n",
      "epoch: 66 cost: 9.338736 train_accuracy: 0.54905 test_accuracy: 0.5481\n",
      "epoch: 67 cost: 9.3063545 train_accuracy: 0.5507 test_accuracy: 0.5492\n",
      "epoch: 68 cost: 9.314104 train_accuracy: 0.5503 test_accuracy: 0.5493\n",
      "epoch: 69 cost: 9.322675 train_accuracy: 0.54985 test_accuracy: 0.5495\n",
      "epoch: 70 cost: 9.318543 train_accuracy: 0.55001664 test_accuracy: 0.5482\n",
      "epoch: 71 cost: 9.299077 train_accuracy: 0.5509833 test_accuracy: 0.55\n",
      "epoch: 72 cost: 9.288985 train_accuracy: 0.55151665 test_accuracy: 0.5494\n",
      "epoch: 73 cost: 9.290917 train_accuracy: 0.5513333 test_accuracy: 0.55\n",
      "epoch: 74 cost: 9.293058 train_accuracy: 0.5513167 test_accuracy: 0.5476\n",
      "epoch: 75 cost: 9.2824335 train_accuracy: 0.55175 test_accuracy: 0.5501\n",
      "epoch: 76 cost: 9.322148 train_accuracy: 0.5499 test_accuracy: 0.5471\n",
      "epoch: 77 cost: 9.327593 train_accuracy: 0.5496333 test_accuracy: 0.5476\n",
      "epoch: 78 cost: 9.308029 train_accuracy: 0.55053335 test_accuracy: 0.5486\n",
      "epoch: 79 cost: 9.280306 train_accuracy: 0.55183333 test_accuracy: 0.5485\n",
      "epoch: 80 cost: 9.266086 train_accuracy: 0.5525333 test_accuracy: 0.5497\n",
      "epoch: 81 cost: 9.241767 train_accuracy: 0.5538167 test_accuracy: 0.55\n",
      "epoch: 82 cost: 9.28058 train_accuracy: 0.5517667 test_accuracy: 0.5506\n",
      "epoch: 83 cost: 9.249138 train_accuracy: 0.55338335 test_accuracy: 0.5513\n",
      "epoch: 84 cost: 9.228677 train_accuracy: 0.55438334 test_accuracy: 0.5516\n",
      "epoch: 85 cost: 9.245977 train_accuracy: 0.5535333 test_accuracy: 0.5512\n",
      "epoch: 86 cost: 9.232989 train_accuracy: 0.5542167 test_accuracy: 0.5516\n",
      "epoch: 87 cost: 9.236716 train_accuracy: 0.55405 test_accuracy: 0.5517\n",
      "epoch: 88 cost: 9.222558 train_accuracy: 0.55476665 test_accuracy: 0.5505\n",
      "epoch: 89 cost: 9.227867 train_accuracy: 0.55443335 test_accuracy: 0.5513\n",
      "epoch: 90 cost: 9.230783 train_accuracy: 0.5542167 test_accuracy: 0.5506\n",
      "epoch: 91 cost: 9.209446 train_accuracy: 0.55535 test_accuracy: 0.5519\n",
      "epoch: 92 cost: 9.205292 train_accuracy: 0.5556 test_accuracy: 0.5527\n",
      "epoch: 93 cost: 9.196406 train_accuracy: 0.556 test_accuracy: 0.5532\n",
      "epoch: 94 cost: 9.226527 train_accuracy: 0.5545 test_accuracy: 0.5511\n",
      "epoch: 95 cost: 9.201221 train_accuracy: 0.55576664 test_accuracy: 0.5528\n",
      "epoch: 96 cost: 9.19244 train_accuracy: 0.55616665 test_accuracy: 0.5529\n",
      "epoch: 97 cost: 9.209209 train_accuracy: 0.5553833 test_accuracy: 0.5531\n",
      "epoch: 98 cost: 9.179297 train_accuracy: 0.55685 test_accuracy: 0.5542\n",
      "epoch: 99 cost: 9.190596 train_accuracy: 0.55623335 test_accuracy: 0.5535\n"
     ]
    }
   ],
   "source": [
    "cost_log = []\n",
    "accuracy_log =[]\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i in range(int(num_data/batch_size)):\n",
    "        x_batch, y_batch = iterater.get_next()\n",
    "\n",
    "        run_optimizer(x_batch, y_batch)\n",
    "\n",
    "    cost_value = cost_function(train_Y, hypothesis(train_X))\n",
    "    cost_log.append(cost_value)\n",
    "    train_accuracy = accuracy(train_Y, hypothesis(train_X))\n",
    "    test_accuracy = accuracy(test_Y, hypothesis(test_X))\n",
    "    accuracy_log.append(test_accuracy)\n",
    "    print(\"epoch:\",epoch,\"cost:\",cost_value.numpy(),\"train_accuracy:\",train_accuracy.numpy(),\"test_accuracy:\",test_accuracy.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cost_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-00759361c8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 비용함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cost_value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cost_log' is not defined"
     ]
    }
   ],
   "source": [
    "# 비용함수\n",
    "plt.plot(np.arange(0,100),cost_log)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('cost_value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
