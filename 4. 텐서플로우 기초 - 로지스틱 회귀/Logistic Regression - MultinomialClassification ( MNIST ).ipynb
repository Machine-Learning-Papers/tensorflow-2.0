{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - MultinomialClassification ( MNIST )\n",
    "softmax를 사용한 로지스틱 다중 분류 예제.   \n",
    "( 딥러닝의 방식인 층을 사용하지 않고 로지스틱회귀로만 푸는 예제 )\n",
    "> 출처\n",
    "1. Andrew NG\n",
    "2. Sung Kim\n",
    "\n",
    "데이터 출처 : MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기 및 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 데이터 불러오기.\n",
    "( train_x, train_y ), (test_x, test_y ) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# MNIST 데이터 파라미터 설정\n",
    "num_classes = 10 # 0부터 9까지의 숫자\n",
    "num_features = 784 # 28*28\n",
    "\n",
    "# 하이퍼파라미터\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "num_data = train_x.shape[0]\n",
    "\n",
    "# 딥러닝이 아닌 간단한 로지스틱 회귀를 위해서 2차원(이미지)를 1차원으로 바꿔준다.\n",
    "train_X = tf.constant(train_x, dtype=tf.float32)\n",
    "train_X = tf.reshape(train_X, [-1,num_features])\n",
    "train_Y = tf.one_hot(train_y, depth=10) # y값 one-hot encoding\n",
    "\n",
    "test_X = tf.constant(test_x, dtype=tf.float32)\n",
    "test_X = tf.reshape(test_X, [-1,num_features])\n",
    "test_Y = tf.one_hot(test_y, depth=10) # y값 one-hot encoding\n",
    "\n",
    "# 데이터 셔플링 및 배치화\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size)\n",
    "iterater = train_data.__iter__()\n",
    "\n",
    "# 파라미터 설정\n",
    "W = tf.Variable(tf.random.normal([num_features,num_classes]))\n",
    "b = tf.Variable(tf.random.normal([num_classes]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설 함수\n",
    "def hypothesis(x):\n",
    "    return tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "# 비용 함수 cross-entropy를 사용한다.\n",
    "def cost_function(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.) # log(0) error를 피하기 위함.\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred),axis=1))\n",
    "\n",
    "# Gradient Descent\n",
    "def run_optimizer(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predict = hypothesis(x)\n",
    "        cost = cost_function(y, predict)\n",
    "\n",
    "    dJ_dW,dJ_db = tape.gradient(cost,[W,b])\n",
    "    W.assign_sub(learning_rate*dJ_dW)\n",
    "    b.assign_sub(learning_rate*dJ_db)\n",
    "    \n",
    "def accuracy(y_true, y_pred):\n",
    "    predict = tf.argmax(y_pred, axis=1)\n",
    "    y_true = tf.argmax(y_true,axis=1)\n",
    "    correct = tf.cast(tf.equal(predict,y_true),dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 18.304104 train_accuracy: 0.11615 test_accuracy: 0.1132\n",
      "epoch: 1 cost: 16.978436 train_accuracy: 0.18 test_accuracy: 0.1752\n",
      "epoch: 2 cost: 16.067318 train_accuracy: 0.2239 test_accuracy: 0.2174\n",
      "epoch: 3 cost: 15.362184 train_accuracy: 0.25816667 test_accuracy: 0.2508\n",
      "epoch: 4 cost: 14.571553 train_accuracy: 0.29608333 test_accuracy: 0.2935\n",
      "epoch: 5 cost: 14.14193 train_accuracy: 0.31703332 test_accuracy: 0.3137\n",
      "epoch: 6 cost: 13.68761 train_accuracy: 0.33868334 test_accuracy: 0.334\n",
      "epoch: 7 cost: 13.386515 train_accuracy: 0.35326666 test_accuracy: 0.3502\n",
      "epoch: 8 cost: 13.187885 train_accuracy: 0.36293334 test_accuracy: 0.3612\n",
      "epoch: 9 cost: 12.955848 train_accuracy: 0.37425 test_accuracy: 0.3733\n",
      "epoch: 10 cost: 12.859248 train_accuracy: 0.37905 test_accuracy: 0.379\n",
      "epoch: 11 cost: 12.672297 train_accuracy: 0.38798332 test_accuracy: 0.386\n",
      "epoch: 12 cost: 12.562221 train_accuracy: 0.39316666 test_accuracy: 0.387\n",
      "epoch: 13 cost: 12.28031 train_accuracy: 0.4069 test_accuracy: 0.4033\n",
      "epoch: 14 cost: 11.783489 train_accuracy: 0.43053332 test_accuracy: 0.4299\n",
      "epoch: 15 cost: 11.483725 train_accuracy: 0.44518334 test_accuracy: 0.443\n",
      "epoch: 16 cost: 11.267656 train_accuracy: 0.45556667 test_accuracy: 0.4547\n",
      "epoch: 17 cost: 11.037907 train_accuracy: 0.46681666 test_accuracy: 0.465\n",
      "epoch: 18 cost: 11.007505 train_accuracy: 0.46821666 test_accuracy: 0.4661\n",
      "epoch: 19 cost: 10.908413 train_accuracy: 0.4731 test_accuracy: 0.4694\n",
      "epoch: 20 cost: 10.683268 train_accuracy: 0.48398334 test_accuracy: 0.4827\n",
      "epoch: 21 cost: 10.568431 train_accuracy: 0.48935 test_accuracy: 0.487\n",
      "epoch: 22 cost: 10.315987 train_accuracy: 0.50158334 test_accuracy: 0.5\n",
      "epoch: 23 cost: 10.183991 train_accuracy: 0.5078833 test_accuracy: 0.5069\n",
      "epoch: 24 cost: 10.108504 train_accuracy: 0.5116 test_accuracy: 0.5087\n",
      "epoch: 25 cost: 9.999095 train_accuracy: 0.5168333 test_accuracy: 0.5168\n",
      "epoch: 26 cost: 9.869494 train_accuracy: 0.52306664 test_accuracy: 0.5204\n",
      "epoch: 27 cost: 9.729262 train_accuracy: 0.5298167 test_accuracy: 0.5291\n",
      "epoch: 28 cost: 9.788477 train_accuracy: 0.5269833 test_accuracy: 0.5275\n",
      "epoch: 29 cost: 9.621075 train_accuracy: 0.5351 test_accuracy: 0.5359\n",
      "epoch: 30 cost: 9.480286 train_accuracy: 0.54188335 test_accuracy: 0.5407\n",
      "epoch: 31 cost: 9.440419 train_accuracy: 0.54396665 test_accuracy: 0.5441\n",
      "epoch: 32 cost: 9.329298 train_accuracy: 0.5492167 test_accuracy: 0.5486\n",
      "epoch: 33 cost: 9.240339 train_accuracy: 0.5534667 test_accuracy: 0.554\n",
      "epoch: 34 cost: 9.208862 train_accuracy: 0.555 test_accuracy: 0.5553\n",
      "epoch: 35 cost: 9.112019 train_accuracy: 0.55973333 test_accuracy: 0.5607\n",
      "epoch: 36 cost: 9.079321 train_accuracy: 0.56121665 test_accuracy: 0.5623\n",
      "epoch: 37 cost: 9.113773 train_accuracy: 0.5596667 test_accuracy: 0.5578\n",
      "epoch: 38 cost: 9.000913 train_accuracy: 0.5650167 test_accuracy: 0.5632\n",
      "epoch: 39 cost: 8.954525 train_accuracy: 0.56738335 test_accuracy: 0.567\n",
      "epoch: 40 cost: 8.877437 train_accuracy: 0.57095 test_accuracy: 0.5694\n",
      "epoch: 41 cost: 8.930897 train_accuracy: 0.56855 test_accuracy: 0.5689\n",
      "epoch: 42 cost: 8.790956 train_accuracy: 0.57533336 test_accuracy: 0.5736\n",
      "epoch: 43 cost: 8.760862 train_accuracy: 0.5767 test_accuracy: 0.5766\n",
      "epoch: 44 cost: 8.714723 train_accuracy: 0.57885 test_accuracy: 0.5769\n",
      "epoch: 45 cost: 8.722049 train_accuracy: 0.57836664 test_accuracy: 0.5779\n",
      "epoch: 46 cost: 8.709901 train_accuracy: 0.5792 test_accuracy: 0.579\n",
      "epoch: 47 cost: 8.654372 train_accuracy: 0.5819 test_accuracy: 0.581\n",
      "epoch: 48 cost: 8.611705 train_accuracy: 0.584 test_accuracy: 0.5827\n",
      "epoch: 49 cost: 8.646316 train_accuracy: 0.5821667 test_accuracy: 0.5799\n",
      "epoch: 50 cost: 8.540732 train_accuracy: 0.5873333 test_accuracy: 0.5844\n",
      "epoch: 51 cost: 8.584593 train_accuracy: 0.58521664 test_accuracy: 0.584\n",
      "epoch: 52 cost: 8.5466585 train_accuracy: 0.58718336 test_accuracy: 0.5872\n",
      "epoch: 53 cost: 8.603476 train_accuracy: 0.58425 test_accuracy: 0.5845\n",
      "epoch: 54 cost: 8.486101 train_accuracy: 0.59008336 test_accuracy: 0.5871\n",
      "epoch: 55 cost: 8.5460205 train_accuracy: 0.5872 test_accuracy: 0.5855\n",
      "epoch: 56 cost: 8.534602 train_accuracy: 0.5876167 test_accuracy: 0.5855\n",
      "epoch: 57 cost: 8.462382 train_accuracy: 0.59106666 test_accuracy: 0.5881\n",
      "epoch: 58 cost: 8.416843 train_accuracy: 0.5934 test_accuracy: 0.5913\n",
      "epoch: 59 cost: 8.427489 train_accuracy: 0.59291667 test_accuracy: 0.5899\n",
      "epoch: 60 cost: 8.377452 train_accuracy: 0.5953 test_accuracy: 0.5927\n",
      "epoch: 61 cost: 8.387636 train_accuracy: 0.59475 test_accuracy: 0.5912\n",
      "epoch: 62 cost: 8.365351 train_accuracy: 0.5958667 test_accuracy: 0.5941\n",
      "epoch: 63 cost: 8.397857 train_accuracy: 0.59415 test_accuracy: 0.5924\n",
      "epoch: 64 cost: 8.362571 train_accuracy: 0.5959333 test_accuracy: 0.5937\n",
      "epoch: 65 cost: 8.325582 train_accuracy: 0.59776664 test_accuracy: 0.5966\n",
      "epoch: 66 cost: 8.297836 train_accuracy: 0.5991167 test_accuracy: 0.5951\n",
      "epoch: 67 cost: 8.277355 train_accuracy: 0.60011667 test_accuracy: 0.5976\n",
      "epoch: 68 cost: 8.333248 train_accuracy: 0.5973667 test_accuracy: 0.5955\n",
      "epoch: 69 cost: 8.340194 train_accuracy: 0.59706664 test_accuracy: 0.5928\n",
      "epoch: 70 cost: 8.298798 train_accuracy: 0.5990833 test_accuracy: 0.5955\n",
      "epoch: 71 cost: 8.31523 train_accuracy: 0.59818333 test_accuracy: 0.5963\n",
      "epoch: 72 cost: 8.32371 train_accuracy: 0.59783334 test_accuracy: 0.595\n",
      "epoch: 73 cost: 8.255919 train_accuracy: 0.60116667 test_accuracy: 0.5987\n",
      "epoch: 74 cost: 8.236568 train_accuracy: 0.60218334 test_accuracy: 0.599\n",
      "epoch: 75 cost: 8.208784 train_accuracy: 0.6034833 test_accuracy: 0.6\n",
      "epoch: 76 cost: 8.2551565 train_accuracy: 0.60115 test_accuracy: 0.5989\n",
      "epoch: 77 cost: 8.366713 train_accuracy: 0.59578335 test_accuracy: 0.5925\n",
      "epoch: 78 cost: 8.222653 train_accuracy: 0.6027167 test_accuracy: 0.5982\n",
      "epoch: 79 cost: 8.27446 train_accuracy: 0.60033333 test_accuracy: 0.5967\n",
      "epoch: 80 cost: 8.207113 train_accuracy: 0.60361665 test_accuracy: 0.5992\n",
      "epoch: 81 cost: 8.223681 train_accuracy: 0.6028 test_accuracy: 0.5986\n",
      "epoch: 82 cost: 8.180524 train_accuracy: 0.6049 test_accuracy: 0.6012\n",
      "epoch: 83 cost: 8.186985 train_accuracy: 0.6045 test_accuracy: 0.6024\n",
      "epoch: 84 cost: 8.178297 train_accuracy: 0.6048167 test_accuracy: 0.6011\n",
      "epoch: 85 cost: 8.188486 train_accuracy: 0.60435 test_accuracy: 0.6003\n",
      "epoch: 86 cost: 8.175464 train_accuracy: 0.60503334 test_accuracy: 0.6012\n",
      "epoch: 87 cost: 8.138682 train_accuracy: 0.60688335 test_accuracy: 0.602\n",
      "epoch: 88 cost: 8.130396 train_accuracy: 0.60733336 test_accuracy: 0.6029\n",
      "epoch: 89 cost: 8.10775 train_accuracy: 0.60833335 test_accuracy: 0.6049\n",
      "epoch: 90 cost: 8.128546 train_accuracy: 0.60726666 test_accuracy: 0.6027\n",
      "epoch: 91 cost: 8.140911 train_accuracy: 0.6067167 test_accuracy: 0.6027\n",
      "epoch: 92 cost: 8.161982 train_accuracy: 0.60581666 test_accuracy: 0.6013\n",
      "epoch: 93 cost: 8.108521 train_accuracy: 0.60838336 test_accuracy: 0.6029\n",
      "epoch: 94 cost: 8.114165 train_accuracy: 0.6081 test_accuracy: 0.6041\n",
      "epoch: 95 cost: 8.085236 train_accuracy: 0.60938334 test_accuracy: 0.6046\n",
      "epoch: 96 cost: 8.069684 train_accuracy: 0.6102 test_accuracy: 0.6062\n",
      "epoch: 97 cost: 8.075333 train_accuracy: 0.6099 test_accuracy: 0.6041\n",
      "epoch: 98 cost: 8.0444 train_accuracy: 0.6114333 test_accuracy: 0.6066\n",
      "epoch: 99 cost: 8.03912 train_accuracy: 0.61165 test_accuracy: 0.6057\n"
     ]
    }
   ],
   "source": [
    "cost_log = []\n",
    "accuracy_log =[]\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i in range(int(num_data/batch_size)):\n",
    "        x_batch, y_batch = iterater.get_next()\n",
    "\n",
    "        run_optimizer(x_batch, y_batch)\n",
    "\n",
    "    cost_value = cost_function(train_Y, hypothesis(train_X))\n",
    "    cost_log.append(cost_value)\n",
    "    train_accuracy = accuracy(train_Y, hypothesis(train_X))\n",
    "    test_accuracy = accuracy(test_Y, hypothesis(test_X))\n",
    "    accuracy_log.append(test_accuracy)\n",
    "    print(\"epoch:\",epoch,\"cost:\",cost_value.numpy(),\"train_accuracy:\",train_accuracy.numpy(),\"test_accuracy:\",test_accuracy.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-00759361c8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 비용함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cost_value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 비용함수\n",
    "plt.plot(np.arange(0,100),cost_log)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('cost_value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
